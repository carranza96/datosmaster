---
title: "Regresión Black Friday"
output:
  html_document:
    df_print: paged
---

```{r message=FALSE}
#install.packages("arulesViz")
install.packages("psych")
library(arules)
library(arulesViz)
library(tidyverse)
library(psych)
```

Carga e inspeccion de los datos del dataset

```{r}
mydata = read.csv("BlackFriday.csv")

head(mydata)
tail(mydata)
str(mydata)
summary(mydata)
psych::describe(mydata)
dim(mydata)

```

Realizamos cambios al tipo de datos de la variable

```{r}
str(mydata)
mydata$Marital_Status = as.factor(mydata$Marital_Status)

```

Hacemos un análisis por cada variable con esta función

```{r}
stat_function = function(x){
    if(class(x)=="integer"|class(x)=="numeric"){
        var_type = class(x)
        length = length(x)
        miss_val = sum(is.na(x))
        mean = mean(x,na.rm = T)
        std = sd(x,na.rm = T)
        var = var(x,na.rm = T)
        cv = std/mean
        min = min(x)
        max = max(x,na.rm = T)
        pct = quantile(x,na.rm = T,p=c(0.75,0.85,0.90,0.95,0.99,1.0))
        return(c(var_type=var_type,length=length,miss_val=miss_val,mean=mean,std=std,var=var,cv=cv,min=min,max=max,pct=pct))
        }
}
```

Nombres de las variables categóricas y numéricas

```{r}
num_var = names(mydata)[sapply(mydata,is.numeric)]
cat_var = names(mydata)[!sapply(mydata,is.numeric)]
```

Aplicamos la función univariante a las variables numéricas

```{r}
mystat = apply(mydata[num_var],2,stat_function)
t(mystat)
```

Comprobamos los outlier en los datos

```{r}
options(scipen = 9999)
boxplot(mydata[num_var],horizontal = T,col = rainbow(1:10))
```

Valores perdidos en los datos

```{r}
t(colSums(is.na(mydata)))
```

Aquí en la variable data 2 solo tenemos valor faltante. 1.product_Cataogery_2 = 166986 es mucho el valor perdido en los datos aprox. 38% 2.product_Catagory_3 = 373299 es también mucho Aquí la variable se cae directamente debido a una gran pérdida de datos, por lo que no repalciamos el valor

```{r}
mydata$Product_Category_2 <- NULL
mydata$Product_Category_3 <- NULL
```

antes de que el modelo de construcción en estrella simplemente suelte la variable única como 1. cust_id, 2. prod_id

```{r}
mydata$User_ID <- NULL
mydata$Product_ID <- NULL
```
Vamos a realizar una predicción por regresión lineal.

1 - Dividimos el dataset en entrenamiento y test.

```{r}
sample = sample(1:nrow(mydata),size = floor(nrow(mydata)*0.7))
train = mydata[sample,]
test = mydata[-sample,]
```

2 - Empezamos a construir el modelo

```{r}
lm_fit = lm(Purchase~.,data = train)
summary(lm_fit)
step = step(lm_fit)
lm_fit2 = lm(Purchase ~ Gender + Age + Occupation + City_Category + Stay_In_Current_City_Years + Marital_Status + Product_Category_1,data= train)
summary(lm_fit2)
```

3 - Predecimos el valor en el test

```{r}
train_prob_purchase = predict(lm_fit2,newdata = train)
train = cbind(train,train_prob_purchase)

test_prob_purchase = predict(lm_fit2,newdata = test)
test = cbind(test,test_prob_purchase)
```

4 - Verificamos el modelo de precisión en el entrenamiento y las pruebas con MAPE (Mean absolute percentage error) , RMSE (Root Mean Square Error), Cor

```{r}
# 1. MAPE
# train
(mean(abs((train$Purchase-train$train_prob_purchase)/train$Purchase)))
# test
(mean(abs((test$Purchase-test$test_prob_purchase)/test$Purchase)))

# 2. RMSE
#train 
(sqrt(mean((train$Purchase-train$train_prob_purchase)**2)))
#test
(sqrt(mean((test$Purchase-test$test_prob_purchase)**2)))

#3.CoR
#train 
(cor(train$Purchase,train$train_prob_purchase))
#test 
(cor(test$Purchase,test$test_prob_purchase))
```

Analizamos el error cometido

```{r}
library(ggplot2)
ggplot(data = train)+geom_bar(mapping = aes(x = Gender,y = Purchase),stat = "identity",position = "stack")
ggtitle("purchase vs Gender(training set)")+xlab("Gender")+ylab("purchase")
```
